{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "import tensorflow as tf\n",
    "import matplotlib \n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from scipy.misc import imread\n",
    "from imgaug import augmenters as iaa\n",
    "import nibabel as nib\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "np.random.seed(6278)\n",
    "tf.set_random_seed(6728)\n",
    "ia.seed(6278)\n",
    "\n",
    "# Generate training data\n",
    "import tensorflow as tf\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# ========= choice of library ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../Dataset/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting ../../Dataset/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../Dataset/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../Dataset/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# get the fashion mnist data set\n",
    "mnist = input_data.read_data_sets('../../Dataset/MNIST/', one_hot=True)\n",
    "x_data, train_label, y_data, test_label = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "x_data_added,x_data_added_label = mnist.validation.images,mnist.validation.labels\n",
    "x_data = x_data.reshape(-1, 28, 28, 1)  # 28x28x1 input img\n",
    "y_data = y_data.reshape(-1, 28, 28, 1)  # 28x28x1 input img\n",
    "x_data_added = x_data_added.reshape(-1, 28, 28, 1)\n",
    "x_data = np.vstack((x_data,x_data_added))\n",
    "train_label = np.vstack((train_label,x_data_added_label))\n",
    "\n",
    "train_batch = np.zeros((60000,28,28,1))\n",
    "test_batch = np.zeros((10000,28,28,1))\n",
    "\n",
    "for x in range(len(x_data)):\n",
    "    train_batch[x,:,:,:] = np.expand_dims(resize(x_data[x,:,:,0],(28,28)),axis=3)\n",
    "# for x in range(len(y_data)):\n",
    "#     test_batch[x,:,:,:] = np.expand_dims(resize(y_data[x,:,:,0],(28,28)),axis=3)\n",
    "\n",
    "# print out the data shape and the max and min value\n",
    "print(train_batch.shape)\n",
    "print(train_batch.max())\n",
    "print(train_batch.min())\n",
    "print(train_label.shape)\n",
    "print(train_label.max())\n",
    "print(train_label.min())\n",
    "print(test_batch.shape)\n",
    "print(test_batch.max())\n",
    "print(test_batch.min())\n",
    "print(test_label.shape)\n",
    "print(test_label.max())\n",
    "print(test_label.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# show small amount of fashion\n",
    "fig=plt.figure(figsize=(15, 15))\n",
    "columns = 10 ; rows = 10\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(np.squeeze(train_batch[i-1]),cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Label : \"+str(np.argmax(train_label[i-1])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     17,
     56,
     150
    ]
   },
   "outputs": [],
   "source": [
    "# import all of the layers\n",
    "def tf_elu(x):\n",
    "    \"\"\" Exponential Linear Unit based on the ICCV 2015 paper\n",
    "    https://arxiv.org/pdf/1511.07289.pdf\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float\n",
    "        The floating point number that is going to be applied to the ELU activation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Data with the same dimensions as the input after ELU\n",
    "\n",
    "    \"\"\"\n",
    "    return tf.nn.elu(x)\n",
    "def d_tf_elu(x):\n",
    "    \"\"\"Derivative of the Exponential Linear Unit base on the ICCV 2015 paper\n",
    "    https://arxiv.org/pdf/1511.07289.pdf\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : type\n",
    "        Description of parameter `x`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    type\n",
    "        Description of returned object.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "\n",
    "def tf_relu(x): return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "def tf_tanh(x): return tf.nn.tanh(x)\n",
    "def d_tf_tanh(x): return 1 - tf_tanh(x) ** 2\n",
    "\n",
    "def tf_sigmoid(x): return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x): return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "def tf_atan(x): return tf.atan(x)\n",
    "def d_tf_atan(x): return 1.0/(1.0 + x**2)\n",
    "\n",
    "def tf_iden(x): return x\n",
    "def d_tf_iden(x): return 1.0\n",
    "\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def softabs(x): return tf.sqrt(x ** 2 + 1e-20)\n",
    "\n",
    "def tf_logcosh(x): return tf.log(tf.cosh(x))\n",
    "def d_tf_logcosh(x): return tf.tanh(x)\n",
    "\n",
    "class FNN():\n",
    "    \"\"\"Fully Connected Neural Network Implemented in Tensorflow\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inc : type\n",
    "        Description of parameter `inc`.\n",
    "    outc : type\n",
    "        Description of parameter `outc`.\n",
    "    act : type\n",
    "        Description of parameter `act`.\n",
    "    d_act : type\n",
    "        Description of parameter `d_act`.\n",
    "    special_init : type\n",
    "        Description of parameter `special_init`.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    w : type\n",
    "        Description of attribute `w`.\n",
    "    m : type\n",
    "        Description of attribute `m`.\n",
    "    v : type\n",
    "        Description of attribute `v`.\n",
    "    act\n",
    "    d_act\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,inc,outc,act=tf_elu,d_act=d_tf_elu,special_init=False):\n",
    "        if special_init:\n",
    "            interval = np.sqrt(6.0 / (inc + outc + 1.0))\n",
    "            self.w  = tf.Variable(tf.random_uniform(shape=(inc, outc),minval=-interval,maxval=interval,dtype=tf.float32,seed=4))\n",
    "        else:\n",
    "            self.w = tf.Variable(tf.random_normal([inc,outc], stddev=0.05,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "\n",
    "    def getw(self): return self.w\n",
    "\n",
    "    def feedforward(self,input=None):\n",
    "        self.input = input\n",
    "        self.layer = tf.matmul(input,self.w)\n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def feedforward_recover(self,input):\n",
    "        self.input_re = input\n",
    "        self.layer_re = tf.matmul(self.w,self.input_re)\n",
    "        self.layerA_re = self.act(self.layer_re)\n",
    "        return self.layerA_re\n",
    "\n",
    "    def backprop(self,gradient=None,which_reg=0):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad = tf.matmul(tf.transpose(grad_part_3),grad_middle)/batch_size\n",
    "        grad_pass = tf.matmul(grad_middle,tf.transpose(self.w))\n",
    "\n",
    "        if which_reg == 0:\n",
    "            grad = grad\n",
    "\n",
    "        if which_reg == 0.5:\n",
    "            grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "\n",
    "        if which_reg == 1:\n",
    "            grad = grad + lamda * tf.sign(self.w)\n",
    "\n",
    "        if which_reg == 1.5:\n",
    "            grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "\n",
    "        if which_reg == 2:\n",
    "            grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "\n",
    "        if which_reg == 2.5:\n",
    "            grad = grad + lamda * 2.0 * self.w\n",
    "\n",
    "        if which_reg == 3:\n",
    "            grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "\n",
    "        if which_reg == 4:\n",
    "            grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1)\n",
    "        v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat *  learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle )))\n",
    "        return grad_pass,update_w\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out,stddev=0.005,which_reg=0,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.w = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg = which_reg\n",
    "\n",
    "    def getw(self): return self.w\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding)\n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "\n",
    "        grad = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = self.w.shape,out_backprop = grad_middle,\n",
    "            strides=[1,stride,stride,1],padding=padding\n",
    "        ) / batch_size\n",
    "\n",
    "        grad_pass = tf.nn.conv2d_backprop_input(input_sizes = [batch_size] + list(grad_part_3.shape[1:]),filter= self.w,out_backprop = grad_middle,\n",
    "            strides=[1,stride,stride,1],padding=padding\n",
    "        )\n",
    "\n",
    "        if self.which_reg == 0:\n",
    "            grad = grad\n",
    "\n",
    "        if self.which_reg == 0.5:\n",
    "            grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "\n",
    "        if self.which_reg == 1:\n",
    "            grad = grad + lamda * tf.sign(self.w)\n",
    "\n",
    "        if self.which_reg == 1.5:\n",
    "            grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "\n",
    "        if self.which_reg == 2:\n",
    "            grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "\n",
    "        if self.which_reg == 2.5:\n",
    "            grad = grad + lamda * 2.0 * self.w\n",
    "\n",
    "        if self.which_reg == 3:\n",
    "            grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "\n",
    "        if self.which_reg == 4:\n",
    "            grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1)\n",
    "        v_hat = self.v / (1-beta2)\n",
    "        adam_middel = learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,tf.multiply(adam_middel,m_hat)  )))\n",
    "        return grad_pass,update_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# hyper class\n",
    "num_epoch = 100; learning_rate = 0.0008; batch_size = 100; print_size = 10\n",
    "lamda = 0.0\n",
    "beta1,beta2,adam_e = 0.9,0.999,1e-8\n",
    "\n",
    "e1 = CNN(3,1,3)\n",
    "e2 = CNN(3,3,6)\n",
    "latent = FNN(5*5*6,5*5*6)\n",
    "d1 = CNN(3,6,3)\n",
    "d2 = CNN(3,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# encoding/decoding (feed forward)\n",
    "x = tf.placeholder(shape=[batch_size,28,28,1],dtype=tf.float32)\n",
    "# y = tf.placeholder(shape=[batch_size,10],dtype=tf.float32)\n",
    "\n",
    "elayer1 = e1.feedforward(x)\n",
    "elayer1_pool = tf.nn.avg_pool(elayer1,strides=[1,2,2,1],ksize=[1,2,2,1],padding='VALID')\n",
    "elayer2 = e2.feedforward(elayer1_pool)\n",
    "elayer2_pool = tf.nn.avg_pool(elayer2,strides=[1,2,2,1],ksize=[1,2,2,1],padding='VALID')\n",
    "\n",
    "elayer2_reshape = tf.reshape(elayer2_pool,[batch_size,-1])\n",
    "latent_layer = latent.feedforward(elayer2_reshape)\n",
    "latent_reshape  = tf.reshape(latent_layer,[batch_size,5,5,6])\n",
    "\n",
    "dlayer1 = d1.feedforward(latent_reshape)\n",
    "dlayer1_uppool = tf.image.resize_bilinear(dlayer1,[13,13])\n",
    "dlayer2 = d2.feedforward(dlayer1_uppool)\n",
    "dlayer2_uppool = tf.image.resize_bilinear(dlayer2,[28,28])\n",
    "\n",
    "print(elayer1,elayer1_pool)\n",
    "print(elayer2,elayer2_pool)\n",
    "print(latent_layer)\n",
    "print(latent_reshape)\n",
    "print(dlayer1,dlayer1_uppool)\n",
    "print(dlayer2,dlayer2_uppool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoding / decoding (back prop)\n",
    "final_layer_sig = tf_sigmoid(dlayer2_uppool)\n",
    "recon_cost = tf.reduce_mean(tf.square(final_layer_sig-x))\n",
    "# binary_reuse = tf.sqrt(dlayer2_uppool**2 + 10e-5)\n",
    "# binary_cost= tf.reduce_mean(\n",
    "#     tf_relu(dlayer2_uppool) - dlayer2_uppool * x + tf.log(1.0+tf.exp(-binary_reuse))\n",
    "# )\n",
    "total_cost = recon_cost \n",
    "\n",
    "# grad\n",
    "recon_grad = (final_layer_sig-x) * d_tf_sigmoid(dlayer2_uppool)\n",
    "# binary_grad= d_tf_relu(dlayer2_uppool) - x - \\\n",
    "#             (dlayer2_uppool/( binary_reuse * (tf.exp(binary_reuse)+1.0)  ) )\n",
    "total_grad = (recon_grad)/batch_size\n",
    "\n",
    "dgrad2_pool = tf.image.resize_bilinear(total_grad,[11,11])\n",
    "dgrad2,dgrad2_up = d2.backprop(dgrad2_pool)\n",
    "dgrad1_pool = tf.image.resize_bilinear(dgrad2,[3,3])\n",
    "dgrad1,dgrad1_up = d1.backprop(dgrad1_pool)\n",
    "\n",
    "dgrad1_reshape = tf.reshape(dgrad1,[batch_size,-1])\n",
    "dgrad_latent,dgrad_latent_up = latent.backprop(dgrad1_reshape)\n",
    "dgrad_latent_reshape = tf.reshape(dgrad_latent,[batch_size,5,5,6])\n",
    "\n",
    "egrad2_pool = tf.image.resize_bilinear(dgrad_latent_reshape,[11,11])\n",
    "egrad2,egrad2_up = e2.backprop(egrad2_pool)\n",
    "egrad1_pool = tf.image.resize_bilinear(egrad2,[26,26])\n",
    "egrad1,egrad1_up = e1.backprop(egrad1_pool)\n",
    "\n",
    "grad_update = dgrad2_up + dgrad1_up + dgrad_latent_up + egrad2_up + egrad1_up\n",
    "\n",
    "print(dgrad2_pool,dgrad2)\n",
    "print(dgrad1_pool,dgrad1)\n",
    "print(dgrad1_reshape)\n",
    "print(dgrad_latent)\n",
    "print(dgrad_latent_reshape)\n",
    "print(egrad2_pool,egrad2)\n",
    "print(egrad1_pool,egrad1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start the session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    for current_data_index in range(0,len(train_batch),batch_size):\n",
    "        current_data = train_batch[current_data_index:current_data_index+batch_size].astype(np.float32)\n",
    "        sess_result = sess.run([total_cost,grad_update],feed_dict={x:current_data})\n",
    "        sys.stdout.write(\n",
    "            '\\r iter: ' + str(iter) + ' batch: ' + str(current_data_index) + ' cost: ' + str(sess_result[0])\n",
    "        )\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    if iter % print_size == 0:\n",
    "        sess_result = sess.run(dlayer2_uppool,feed_dict={x:current_data})\n",
    "        \n",
    "        fig=plt.figure(figsize=(15, 15))\n",
    "        columns = 10 ; rows = 10\n",
    "        for i in range(1, columns*rows +1):\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            \n",
    "            if i % 2 ==0 :\n",
    "                  plt.imshow(np.squeeze(sess_result[i-1]),cmap='gray')\n",
    "            else:\n",
    "                plt.imshow(np.squeeze(current_data[i-1]),cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# convert every data into latent to know the statistics\n",
    "all_latent_vectors = []\n",
    "print(train_batch.shape)\n",
    "for current_batch_index in range(0,5000, batch_size):\n",
    "    current_train_data = train_batch[current_batch_index:current_batch_index+batch_size]\n",
    "    sess_results = sess.run(layer3,feed_dict={x:current_train_data})\n",
    "    all_latent_vectors.append(sess_results)\n",
    "all_latent_vectors = np.asarray(all_latent_vectors)\n",
    "print(all_latent_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#  use high level apis to view the data\n",
    "all_latent_vectors = all_latent_vectors.reshape(50*100,-1)\n",
    "print(all_latent_vectors.shape)\n",
    "from sklearn.decomposition import PCA\n",
    "sk_pca = PCA(n_components=3)\n",
    "sk_data = sk_pca.fit_transform(all_latent_vectors)\n",
    "print(sk_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create 3D graph from PCA\n",
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "color_dict = {\n",
    "    0:'red',\n",
    "    1:'blue',\n",
    "    2:'green',\n",
    "    3:'yellow',\n",
    "    4:'purple',\n",
    "    5:'grey',\n",
    "    6:'black',\n",
    "    7:'violet',\n",
    "    8:'silver',\n",
    "    9:'cyan',\n",
    "}\n",
    "color_mapping = [color_dict[x] for x in np.argmax(train_label[:5000,:],1) ]\n",
    "ax.scatter(sk_data[:,0], sk_data[:,1], sk_data[:,2],c=color_mapping)\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "ax.grid(True)\n",
    "plt.title(\n",
    "    \"\"\"red : T-shirt/top, blue : Trouse, green: Pullover, yellow : Dress, purple : Coat\n",
    "    \\n\n",
    "    grey : Sandal, black : Shirt, violet : Sneaker, silver : Bag, cyan : Ankle boot\"\"\"\n",
    "    ,fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination of PCA and tsne\n",
    "sk_pca_2 = PCA(n_components=10)\n",
    "sk_data_2 = sk_pca_2.fit_transform(all_latent_vectors)\n",
    "print(sk_data_2.shape)\n",
    "# use the TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "sk_TSNE = TSNE(n_components=3, random_state=0)\n",
    "sk_tsne_data = sk_TSNE.fit_transform(sk_data_2)\n",
    "print(sk_tsne_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the data\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "color_dict = {\n",
    "    0:'red',\n",
    "    1:'blue',\n",
    "    2:'green',\n",
    "    3:'yellow',\n",
    "    4:'purple',\n",
    "    5:'grey',\n",
    "    6:'black',\n",
    "    7:'violet',\n",
    "    8:'silver',\n",
    "    9:'cyan',\n",
    "}\n",
    "color_mapping = [color_dict[x] for x in np.argmax(train_label[:5000,:],1) ]\n",
    "ax.scatter(sk_tsne_data[:,0], sk_tsne_data[:,1], sk_tsne_data[:,2],c=color_mapping)\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "ax.grid(True)\n",
    "plt.title(\n",
    "    \"\"\"red : T-shirt/top, blue : Trouse, green: Pullover, yellow : Dress, purple : Coat\n",
    "    \\n\n",
    "    grey : Sandal, black : Shirt, violet : Sneaker, silver : Bag, cyan : Ankle boot\"\"\"\n",
    "    ,fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git add .\n",
    "! git commit -m \"from mac\"\n",
    "! git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
