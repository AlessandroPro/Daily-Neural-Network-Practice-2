{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "# ========= choice of library ====\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.misc import imread,imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "import nibabel as nib\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "np.random.seed(6278)\n",
    "tf.set_random_seed(6728)\n",
    "ia.seed(6278)\n",
    "\n",
    "# Generate training data\n",
    "import tensorflow as tf\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# ========= choice of library ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "1.0\n",
      "0.0\n",
      "(50000, 10)\n",
      "1.0\n",
      "0.0\n",
      "(10000, 32, 32, 3)\n",
      "1.0\n",
      "0.0\n",
      "(10000, 10)\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Get the CIFAR 10 Data\n",
    "# ====== miscellaneous =====\n",
    "# code from: https://github.com/tensorflow/tensorflow/issues/8246\n",
    "def tf_repeat(tensor, repeats):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "\n",
    "    input: A Tensor. 1-D or higher.\n",
    "    repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats\n",
    "    \"\"\"\n",
    "    expanded_tensor = tf.expand_dims(tensor, -1)\n",
    "    multiples = [1] + repeats\n",
    "    tiled_tensor = tf.tile(expanded_tensor, multiples = multiples)\n",
    "    repeated_tesnor = tf.reshape(tiled_tensor, tf.shape(tensor) * repeats)\n",
    "    return repeated_tesnor\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "# ====== miscellaneous =====\n",
    "\n",
    "# data\n",
    "PathDicom = \"../../Dataset/cifar-10-batches-py/\"\n",
    "lstFilesDCM = []  # create an empty list\n",
    "for dirName, subdirList, fileList in os.walk(PathDicom):\n",
    "    for filename in fileList:\n",
    "        if not \".html\" in filename.lower() and not  \".meta\" in filename.lower():  # check whether the file's DICOM\n",
    "            lstFilesDCM.append(os.path.join(dirName,filename))\n",
    "\n",
    "# Read the data traind and Test\n",
    "batch0 = unpickle(lstFilesDCM[0])\n",
    "batch1 = unpickle(lstFilesDCM[1])\n",
    "batch2 = unpickle(lstFilesDCM[2])\n",
    "batch3 = unpickle(lstFilesDCM[3])\n",
    "batch4 = unpickle(lstFilesDCM[4])\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=True)\n",
    "train_batch = np.vstack((batch0[b'data'],batch1[b'data'],batch2[b'data'],batch3[b'data'],batch4[b'data']))\n",
    "train_label = np.expand_dims(np.hstack((batch0[b'labels'],batch1[b'labels'],batch2[b'labels'],batch3[b'labels'],batch4[b'labels'])).T,axis=1).astype(np.float64)\n",
    "train_label = onehot_encoder.fit_transform(train_label).toarray().astype(np.float64)\n",
    "\n",
    "test_batch = unpickle(lstFilesDCM[5])[b'data']\n",
    "test_label = np.expand_dims(np.array(unpickle(lstFilesDCM[5])[b'labels']),axis=0).T.astype(np.float64)\n",
    "test_label = onehot_encoder.fit_transform(test_label).toarray().astype(np.float64)\n",
    "\n",
    "# reshape data\n",
    "train_batch = np.reshape(train_batch,(len(train_batch),3,32,32))\n",
    "test_batch = np.reshape(test_batch,(len(test_batch),3,32,32))\n",
    "\n",
    "# rotate data\n",
    "train_batch = np.rot90(np.rot90(train_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64)\n",
    "test_batch = np.rot90(np.rot90(test_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64)\n",
    "\n",
    "# normalize\n",
    "train_batch= test_batch/255.0\n",
    "test_batch = test_batch/255.0\n",
    "\n",
    "# print out the data shape and the max and min value\n",
    "print('Train batch, min, max : ',train_batch.shape,train_batch.min(),train_batch.max())\n",
    "print('Train Label, min, max : ',train_label.shape,train_label.min(),train_label.max())\n",
    "print('Test Label, min, max : ',test_batch.shape,test_batch.min(),test_batch.max())\n",
    "print('Test Label, min, max : ',train_label.shape,train_label.min(),train_label.max())\n",
    "\n",
    "print(train_label.shape)\n",
    "print(train_label.max())\n",
    "print(train_label.min())\n",
    "print(test_batch.shape)\n",
    "print(test_batch.max())\n",
    "print(test_batch.min())\n",
    "print(test_label.shape)\n",
    "print(test_label.max())\n",
    "print(test_label.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 34f95b88] s\n",
      " 4 files changed, 411 insertions(+), 8 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in Understanding_Concepts/deep_ica/.ipynb_checkpoints/a deep ica-checkpoint.ipynb.\n",
      "The file will have its original line endings in your working directory.\n",
      "warning: LF will be replaced by CRLF in Understanding_Concepts/deep_ica/a deep ica.ipynb.\n",
      "The file will have its original line endings in your working directory.\n",
      "To https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2\n",
      "   03135921..34f95b88  master -> master\n"
     ]
    }
   ],
   "source": [
    "! git all-go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! start ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
