{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from numpy import dot\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "n_samples = 2000\n",
    "time = np.linspace(0, 8, n_samples)\n",
    "\n",
    "s1 = np.sin(2 * time)  # Signal 1 : sinusoidal signal\n",
    "s2 = np.sign(np.sin(3 * time))  # Signal 2 : square signal\n",
    "s3 = signal.sawtooth(2 * np.pi * time)  # Signal 3: saw tooth signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal Matrix :  (2000, 3)\n",
      "Mix Matrix :  (3, 3)\n",
      "Transform Matrix:  (2000, 3)\n",
      "Mean of Transformed :  0.21366672951061594\n"
     ]
    }
   ],
   "source": [
    "# Mix the Signals\n",
    "S = np.c_[s1, s2, s3]\n",
    "S += 0.2 * np.random.normal(size=S.shape)  # Add noise\n",
    "S /= S.std(axis=0)  # Standardize data\n",
    "\n",
    "# Mix data\n",
    "A = np.array([[1, 1, 1], [0.5, 2, 1.0], [1.5, 1.0, 2.0]])  # Mixing matrix\n",
    "X = np.dot(S, A.T)  # Generate observations\n",
    "\n",
    "print(\"Signal Matrix : \", S.shape)\n",
    "print(\"Mix Matrix : \", A.shape)\n",
    "print(\"Transform Matrix: \", X.shape)\n",
    "print(\"Mean of Transformed : \", X.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ICA\n",
    "ica = FastICA(n_components=3)\n",
    "S_ica = ica.fit_transform(X)  # Reconstruct signals\n",
    "A_ = ica.mixing_  # Get estimated mixing matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison, compute PCA\n",
    "pca = PCA(n_components=3)\n",
    "S_pca = pca.fit_transform(X)  # Reconstruct signals based on orthogonal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Parameters for Gradient\n",
    "num_epoch = 15000\n",
    "learning_rate = 0.00001\n",
    "\n",
    "def np_sig(x):return  1 /(1+(np.exp(-x)))\n",
    "def np_tanh(x): return np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparsion ICA with gradient (gradient)\n",
    "w_sig_grad = np.eye(3)\n",
    "for iter in range(num_epoch):\n",
    "    grad = np.linalg.inv(w_sig_grad.T) + dot(np_sig(dot(X,w_sig_grad)).T,X)\n",
    "    w_sig_grad = w_sig_grad + learning_rate * grad\n",
    "S_sig_grad = dot(X, w_sig_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparsion ICA with gradient (adam)\n",
    "w_sig_adam = np.eye(3)\n",
    "v_sig_adam = np.zeros_like(w_sig_adam)\n",
    "m_sig_adam = np.zeros_like(w_sig_adam)\n",
    "\n",
    "for iter in range(num_epoch):\n",
    "    grad = np.linalg.inv(w_sig_adam.T) + dot(np_sig(dot(X,w_sig_adam)).T,X)\n",
    "    \n",
    "    m_sig_adam = 0.9 * m_sig_adam + (1-0.9) * grad\n",
    "    v_sig_adam = 0.999 * v_sig_adam + (1-0.999) * grad ** 2\n",
    "    \n",
    "    m_hat = m_sig_adam/(1-0.9)\n",
    "    v_hat = v_sig_adam/(1-0.999)\n",
    "    w_sig_adam = w_sig_adam + learning_rate*0.0007/np.sqrt(v_hat + 1e-30) * m_hat   \n",
    "\n",
    "S_sig_adam = dot(X,w_sig_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparsion ICA with gradient another method\n",
    "w_tanh_grad = np.eye(3)\n",
    "for current_iter in range(num_epoch):\n",
    "    u = dot(X,w_tanh_grad)\n",
    "    U = np_tanh(u)\n",
    "    g = np.linalg.inv(w_tanh_grad.T) - (2/len(X)) * dot(X.T,U)\n",
    "    w_tanh_grad = w_tanh_grad + learning_rate *g\n",
    "S_tanh_grad = dot(X,w_tanh_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparsion ICA with gradient another method (adam)\n",
    "w_tanh_adam = np.eye(3)\n",
    "m_tanh_adam = np.zeros_like(w_tanh_adam)\n",
    "v_tanh_adam = np.zeros_like(w_tanh_adam)\n",
    "\n",
    "for current_iter in range(num_epoch):\n",
    "    u = dot(X,w_tanh_adam)\n",
    "    \n",
    "    U = np_tanh(u)\n",
    "    grad = np.linalg.inv(w_tanh_adam.T) - (2/len(X)) * dot(X.T,U)\n",
    "    \n",
    "    m_tanh_adam = 0.9 * m_tanh_adam + (1-0.9) * grad\n",
    "    v_tanh_adam = 0.999 * v_tanh_adam + (1-0.999) * grad ** 2\n",
    "    \n",
    "    m_hat = m_tanh_adam/(1-0.9)\n",
    "    v_hat = v_tanh_adam/(1-0.999)\n",
    "    w_tanh_adam = w_tanh_adam + learning_rate/np.sqrt(v_hat + 1e-30) * m_hat   \n",
    "    \n",
    "S_tanh_adam = dot(X,w_tanh_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "S_tf = None\n",
    "x_tf = tf.placeholder(shape=[2000,3],dtype=tf.float32)\n",
    "w_tf = tf.Variable(tf.eye(3))\n",
    "\n",
    "u_tf = tf.matmul(x_tf,w_tf)\n",
    "U_tf = tf.nn.tanh(u_tf)\n",
    "g_tf = tf.linalg.inv(tf.transpose(w_tf)) - (2/len(X)) * tf.matmul(tf.transpose(x_tf),U_tf)\n",
    "w_tf_update = [tf.assign(w_tf,w_tf+learning_rate*g_tf)]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for iter in range(num_epoch):\n",
    "        sess_result = sess.run(w_tf_update,feed_dict={x_tf:X.astype(np.float32)})\n",
    "    S_tf = sess.run(u_tf,feed_dict={x_tf:X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Data Shape',S.shape)\n",
    "print('Fast ICA Data Shape',S_ica.shape)\n",
    "print('PCA Data Shape',S_pca.shape)\n",
    "print('Sigmoid Grad Data Shape',S_sig_grad.shape)\n",
    "print('Sigmoid Adam Data Shape',S_sig_adam.shape)\n",
    "print('Tanh Grad Data Shape',S_tanh_grad.shape)\n",
    "print('Tanh Adam Data Shape',S_tanh_adam.shape)\n",
    "print('TF Tanh Grad Data Shape',S_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.hstack((S, S_ica, S_pca,S_sig_grad,S_sig_adam,S_tanh_grad,S_tanh_adam,S_tf)),\n",
    "                 columns=['Og 1','Og 2','Og 3',\n",
    "                         'ICA 1','ICA 2','ICA 3',\n",
    "                         'PCA 1','PCA 2','PCA 3',\n",
    "                         'Sig Grad 1','Sig Grad 2','Sig Grad 3',\n",
    "                         'Sig Adam 1','Sig Adam 2','Sig Adam 3',\n",
    "                         'Tan Grad 1','Tan Grad 2','Tan Grad 3',\n",
    "                         'Tan Adam 1','Tan Adam 2','Tan Adam 3',\n",
    "                       'TF Tan Grad 1','TF Tan Grad 2','TF Tan Grad 3',\n",
    "                         ])\n",
    "plt.figure(figsize=(20,20))\n",
    "ax = sns.heatmap(np.around(df.corr(),2),annot=True,annot_kws={\"size\": 13})\n",
    "ax.vlines([3, 6, 9,12,15,18,21], *ax.get_ylim())\n",
    "ax.hlines([3, 6, 9,12,15,18,21], *ax.get_xlim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Plot results\n",
    "plt.figure(figsize=(18,30))\n",
    "models = [X, S, S_ica, \n",
    "          S_pca,S_sig_grad,S_sig_adam,\n",
    "          S_tanh_grad,S_tanh_adam,S_tf]\n",
    "names = ['Observations (mixed signal)',\n",
    "         'True Sources',\n",
    "         'ICA recovered signals',\n",
    "         'PCA recovered signals',\n",
    "        'Sig Grad Signals',\n",
    "        'Sig Adam Signals',\n",
    "        'Tanh Grad Signals',\n",
    "        'Tanh Adam Signals',\n",
    "        'TF Tanh Grad Signals',\n",
    "        ]\n",
    "colors = ['red', 'steelblue', 'orange']\n",
    "\n",
    "for ii, (model, name) in enumerate(zip(models, names), 1):\n",
    "    plt.subplot(9, 1, ii)\n",
    "    plt.title(name)\n",
    "    for sig, color in zip(model.T, colors):\n",
    "        plt.plot(sig/np.std(sig), color=color)\n",
    "plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.46)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
